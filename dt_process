#!/usr/bin/env python3

import glob
import argparse
from posixpath import split
import client_interface
import re
import sys
import os
import time
import json
import libtags
import tempfile
import shutil
import subprocess
import wavfile
import multiprocessing
import tqdm
import platform
from multiprocessing import Pool, TimeoutError

release_regex = re.compile(r"[\[]r([0-9]+)[\]][.][a-zA-Z]+$")
fregex = re.compile(r"([0-9]+)(([a-zA-Z)+[0-9]*)|[.]([a-zA-Z0-9. ]+))[.]([a-zA-Z]+)$")
pregex = re.compile(r"([a-zA-Z]+)([0-9]+)")

class ConversionException(Exception):
    pass

# Worker process configuration (set by pool initializer for spawn context)
worker_config = {
    'verbose': False,
    'legacy_normalize': False,
    'outdir': None,
    'tmpdir': None
}

def worker_init(config):
    """Initialize worker process with shared configuration."""
    global worker_config
    worker_config = config

def debug(*strs):
    if not worker_config['verbose']:
        return
    print(multiprocessing.current_process().name, strs)

def file_extension(path):
    return "." + path.rsplit(".", 1)[1]

def new_tmp(ext):
    fo, tmppath = tempfile.mkstemp(suffix=ext, dir=worker_config['tmpdir'])
    os.close(fo)
    debug("New temp %s file: %s" % (ext, tmppath))
    return tmppath

def copy_to_tmp(path):
    ext = file_extension(path)
    tmpfil = new_tmp(ext)
    debug("Copying %s to temporary location %s..." % (path, tmpfil))
    shutil.copy(path, tmpfil)
    return tmpfil

# Moves file to new filename with metadata applied
def process_file(path, outdir, track):
    af = libtags.AudioFile(path, track)
    af.commit()
    dest = af.rename_file(outdir, worker_config['verbose'], False, True, False)
    debug("Renamed %s -> %s:" % (path, dest))

# Two-pass EBU R128 loudness normalization using ffmpeg
# Returns path to normalized file (tmpaiff)
def normalize_loudnorm(path, tmpaiff):
    debug("Analyzing loudness (pass 1)...")

    # Pass 1: Analyze the file
    result = subprocess.run([
        "ffmpeg", "-hide_banner", "-i", path,
        "-af", "loudnorm=I=-14:TP=-1:LRA=11:print_format=json",
        "-f", "null", "-"
    ], capture_output=True, text=True)

    # Parse the JSON output from stderr (ffmpeg outputs to stderr)
    # The JSON is at the end of the output after the loudnorm stats
    output = result.stderr
    json_start = output.rfind('{')
    json_end = output.rfind('}') + 1
    if json_start == -1 or json_end == 0:
        raise ConversionException("Failed to parse loudnorm analysis output")

    try:
        stats = json.loads(output[json_start:json_end])
    except json.JSONDecodeError as e:
        debug("loudnorm output:", output)
        raise ConversionException(f"Failed to parse loudnorm JSON: {e}")

    debug("Loudness stats:", stats)

    # Pass 2: Apply normalization with measured values and convert to AIFF
    debug("Normalizing and converting to 44.1/16 AIFF (pass 2)...")

    loudnorm_filter = (
        f"loudnorm=I=-14:TP=-1:LRA=11:"
        f"measured_I={stats['input_i']}:"
        f"measured_TP={stats['input_tp']}:"
        f"measured_LRA={stats['input_lra']}:"
        f"measured_thresh={stats['input_thresh']}:"
        f"offset={stats['target_offset']}:"
        f"linear=true"
    )

    retval = subprocess.call([
        "ffmpeg", "-hide_banner", "-loglevel", "panic",
        "-y", "-i", path,
        "-af", loudnorm_filter,
        "-sample_fmt", "s16", "-ar", "44100",
        tmpaiff
    ])

    if retval:
        raise ConversionException("Loudnorm normalization failed")

# Legacy peak normalization using normalize-audio
def normalize_legacy(path):
    debug("Normalizing (legacy peak mode)...")
    norm_exe = "normalize-audio"
    # Ubuntu calls it normalize-audio, but homebrew normalize. Same program.
    if shutil.which(norm_exe) is None:
        norm_exe = "normalize"
        if shutil.which(norm_exe) is None:
            raise ConversionException("missing normalize utility")

    retval = subprocess.call([norm_exe, "-q", "-T", "1.5", "--peak", path])
    if retval:
        raise ConversionException("Normalization failed")

# if copy, don't do anything the modifies in place
# if not copy, delete path when we are done
def process_wav_file(path, outdir, track, copy):
    tmpaiff = new_tmp(".aiff")

    if copy:
        path = copy_to_tmp(path)

    if worker_config['legacy_normalize']:
        normalize_legacy(path)
        debug("Converting to 44.1/16 AIFF...")
        retval = subprocess.call(["ffmpeg", "-hide_banner", "-loglevel", "panic",
                "-y",  "-i", path, "-sample_fmt", "s16", "-ar", "44100",
                tmpaiff])
        if retval:
            raise ConversionException("Encoding failed")
    else:
        # EBU R128 loudnorm (default) - normalizes and converts in one step
        normalize_loudnorm(path, tmpaiff)

    process_file(tmpaiff, outdir, track)

def process_flac_file(path, outdir, track):
    tmpwav = new_tmp(".wav")
    debug("Converting to intermediate .wav...")
    retval = subprocess.call(["flac", "--silent", "-f", "-d", "-o", tmpwav, path])
    if retval:
        raise ConversionException("FLAC decoding failed")
    process_wav_file(tmpwav, outdir, track, False)

def process_mp3_file(path, outdir, track, copy):
    # Make a copy and process the copied file
    tmpfil = copy_to_tmp(path)
    process_file(tmpfil, outdir, track)

def get_wav_regions_from_markers(markerslist, file_length, rate, min_len):
    """Build regions from markers that have explicit lengths (ltxt chunks)."""
    regions = []
    for m in markerslist:
        start = m['position']
        length = m.get('length', 0)
        if length > 0:
            end = start + length
            duration = length / rate
            if duration >= min_len:
                debug("Region from ltxt: (%d, %d), %d seconds" % (start, end, duration))
                regions.append((start, end))
    return regions

def get_wav_regions(markers, rate, min_len):
    """Build regions from consecutive marker positions (fallback)."""
    regions = []
    for i in range(len(markers) - 1):
        start = markers[i]     # inclusive
        end = markers[i + 1]   # not inclusive
        duration = (end - start) / rate;
        if (duration < min_len):
            continue

        debug("Region (%d, %d), %d seconds" % (start, end, duration))
        regions.append((start, end))
    return regions

def split_wav_file(path, outdir, releaseid):
    rel = client_interface.DiscogsRelease(releaseid)
    debug("SPLIT %s (%s)" % (path, rel))

    try:
        rate, rdata, bits, markers, markerslist, loops = wavfile.read(path, readmarkers=True, readmarkerslist=True, readloops=True)
    except Exception:
        print("Bad wav file %s?" % path)
        raise

    debug("%d samples" % len(rdata))
    file_length = len(rdata)
    debug("Markerslist:", markerslist)
    debug("Loops (smpl chunk):", loops)

    # First, try to use loops from smpl chunk (Reaper exports regions as loops)
    regions = []
    for start, end in loops:
        duration = (end - start) / rate
        if duration >= 30:
            debug("Region from smpl loop: (%d, %d), %d seconds" % (start, end, int(duration)))
            regions.append((start, end))

    if len(regions) != rel.getTotalTracks():
        # Try with smaller minimum duration
        regions = []
        for start, end in loops:
            duration = (end - start) / rate
            if duration >= 6:
                debug("Region from smpl loop: (%d, %d), %d seconds" % (start, end, int(duration)))
                regions.append((start, end))

    # Next, try explicit region lengths from ltxt chunks
    if len(regions) != rel.getTotalTracks():
        regions = get_wav_regions_from_markers(markerslist, file_length, rate, 30)
        if len(regions) != rel.getTotalTracks():
            regions = get_wav_regions_from_markers(markerslist, file_length, rate, 6)

    # Fall back to consecutive marker positions if no ltxt regions found
    if len(regions) != rel.getTotalTracks():
        debug("No ltxt regions, falling back to marker positions")
        markers = list(markers)  # copy
        markers.extend([0, file_length])
        markers.sort()

        debug("Markers:", markers)
        regions = get_wav_regions(markers, rate, 30)

        if len(regions) != rel.getTotalTracks():
            # Try again with smaller second gaps
            # Thanks, Giegling 20 and STL
            regions = get_wav_regions(markers, rate, 6)

    if len(regions) != rel.getTotalTracks():
        raise ConversionException("Unexpected region count %d in %s (%s)" %
                (len(regions), rel, path))

    created = []
    pos_seen = []
    for i in range(rel.getTotalTracks()):
        start, end = regions[i]
        tdata = rdata[start:end]
        track = rel.getTrack(i)
        pos = track["position"]
        if pos in pos_seen:
            raise ConversionException("dupe pos %s in release %s fix on Discogs" %
                (pos, rel))
        else:
            pos_seen.append(pos)

        filename = os.path.join(outdir, "%d.%s.wav" % (rel.getId(), pos))
        debug("Writing %s..." % filename)
        wavfile.write(filename, rate, tdata, bitrate=bits)
        created.append((track, filename, "wav", False))
    debug("DONE %s (%s)" % (path, rel))
    return created

def get_possible_positions(position):
    ret = [position]

    # A1 might just be A
    if position[-1] == "1":
        ret.append(position[:-1])
    elif not position[-1].isdigit():
        # ... or A might actually be A1
        ret.append(position + "1")

    ret2 = []
    for item in ret:
        ret2.append(item)
        if item[0] == "B":
            ret2.append("AA" + item[1:])
    ret = ret2

    ret2 = []
    # Some people do this, annoying
    for item in ret:
        ret2.append(item)
        ret2.append(item + ".")

        # 1B instead of B1, seen this at least once
        m = pregex.match(item)
        if m:
            l, n = m.groups()
            ret2.append("%s%s" % (n, l))

    ret = ret2

    return ret2

def get_release_and_track(releaseid, position):
    rel = client_interface.DiscogsRelease(releaseid)

    rdata = rel.data
    if not rdata:
        print(("Release %d not found" % releaseid))
        return None

    positions = get_possible_positions(position.upper())

    for i in range(len(rdata["tracklist"])):
        track = rdata["tracklist"][i]
        tp = track["position"].upper()
        for p in positions:
            if p == tp:
                return rel.getTrack(i)

    print("Couldn't find position %s in release %s" %
		    (position, rdata["title"]))
    return None

def process_track(trackinfo):
    print(trackinfo)
    track, path, extension, copy = trackinfo
    outdir = worker_config['outdir']

    debug(path, "-->", track)

    if extension == "wav":
        process_wav_file(path, outdir, track, copy)
    elif extension == "flac":
        process_flac_file(path, outdir, track)
    elif extension == "mp3":
        process_mp3_file(path, outdir, track, copy)
    else:
        print("Don't know how to handle", path)
        return

def poolsplit(item):
    path, tmpdir, releaseid = item

    return split_wav_file(path, tmpdir, releaseid)

parser = argparse.ArgumentParser(
        description="Convert WAV/FLAC files to AIFF and tag them")
parser.add_argument("files", metavar="FILE", type=str, nargs="+",
                    help="Files to convert")
parser.add_argument("-o", "--outdir", required=True,
                    help="Base output directory for processed files")
parser.add_argument("-v", "--verbose", action="store_true",
                    help="Enable extra debug messages")
parser.add_argument("-j", "--jobs", type=int,
                    default=multiprocessing.cpu_count(),
                    help="Number of parallel jobs for normalization (default: CPU count)")
parser.add_argument("--legacy-normalize", action="store_true",
                    help="Use legacy peak normalization instead of EBU R128 loudnorm")

def main():
    args = parser.parse_args(sys.argv[1:])

    tracks = []
    files = args.files
    solo_tracks = []
    split_wavs = []

    os.makedirs(args.outdir, exist_ok=True)
    tmpdir = tempfile.mkdtemp()

    # Initialize worker config for main process and workers
    worker_config.update({
        'verbose': args.verbose,
        'legacy_normalize': args.legacy_normalize,
        'outdir': args.outdir,
        'tmpdir': tmpdir
    })

    try:
        for path in files:
            filename = os.path.basename(path)
            m = release_regex.match(filename)
            if not m:
                continue
            releaseid = int(m.group(1))
            split_wavs.append((path, tmpdir, releaseid))

        if split_wavs:
            print("Split multi-track .wav files...")
            # Splitting is I/O bound and uses numpy, run sequentially
            result = []
            for path, td, releaseid in split_wavs:
                result.append(split_wav_file(path, td, releaseid))

            for res in result:
                tracks.extend(res)

        for path in files:
            filename = os.path.basename(path)
            m = fregex.match(filename)
            if not m:
                debug('Skipping', filename)
                continue
            releaseid = m.group(1)
            extension = m.group(5)
            position = m.group(3).upper() if m.group(3) else m.group(4)
            extension = extension.lower()
            releaseid = int(releaseid)

            track = get_release_and_track(releaseid, position)
            if not track:
                print("Couldn't look up", filename)
                sys.exit(1)
            tracks.append((track, path, extension, True))

        print("Tag/normalize/convert audio files...")

        if len(tracks) > 1:
            # Parallel processing using spawn context (works on all platforms)
            with multiprocessing.get_context("spawn").Pool(
                    args.jobs,
                    initializer=worker_init,
                    initargs=(worker_config,)) as p:
                result = list(tqdm.tqdm(p.imap_unordered(process_track, tracks),
                                        total=len(tracks)))
        else:
            # Single track, no need for pool overhead
            for trackinfo in tracks:
                process_track(trackinfo)

    except:
        raise
    finally:
        shutil.rmtree(tmpdir, ignore_errors=True)

if __name__ == '__main__':
    main()
